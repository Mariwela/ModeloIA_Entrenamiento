{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF6DnUjPgnMR+0AkMsY+Ol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariwela/ModeloIA_Entrenamiento/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 0\n",
        "!pip install --upgrade google-genai beautifulsoup4 requests tenacity\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUBwqgKpmTNS",
        "outputId": "8e251010-75e1-4b53-e9de-17f87854783f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.52.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.14.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (9.1.2)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 1\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import threading\n",
        "from queue import Queue, Empty\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "from google import genai\n",
        "\n",
        "#  PON AQU TU API KEY DE FORMA SEGURA (opci贸n 1 recomendada)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCPxji0P2RhGdTAanpDKnKc2Ml13WiLWWQ\"\n",
        "\n",
        "# Crear cliente Gemini\n",
        "client = genai.Client()\n"
      ],
      "metadata": {
        "id": "BDtmP2y7mXkx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 2\n",
        "def safe_get(\n",
        "  url, headers=None, timeout=10):\n",
        "    headers = headers or {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                      \"Chrome/142.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "    resp = requests.get(url, headers=headers, timeout=timeout)\n",
        "    resp.raise_for_status()\n",
        "    return resp.text\n",
        "\n",
        "def extraer_texto_url(url: str) -> str:\n",
        "    \"\"\"Devuelve el texto limpio de una p谩gina web.\"\"\"\n",
        "    html = safe_get(url)\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    # eliminar scripts y estilos\n",
        "    for s in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
        "        s.extract()\n",
        "    textos = list(soup.stripped_strings)\n",
        "    return \" \".join(textos)\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 1500, overlap: int = 200) -> List[str]:\n",
        "    \"\"\"\n",
        "    Divide texto en chunks que respeten l铆mites de tokens aproximados.\n",
        "    Valores por defecto pensados para modelos que manejan ~8k tokens.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        chunk = words[i:i+chunk_size]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "        i += (chunk_size - overlap)\n",
        "    return chunks\n",
        "\n",
        "def save_json(path: str, data: Any):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def load_json(path: str):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n"
      ],
      "metadata": {
        "id": "0CcDyUE_mc57"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 3\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8),\n",
        "       retry=retry_if_exception_type(Exception))\n",
        "def generar_con_gemini(prompt: str, model: str = \"gemini-2.5-flash\", max_output_chars: int = 4000) -> str:\n",
        "    \"\"\"\n",
        "    Llamada robusta a Gemini. Limita la longitud del prompt por seguridad.\n",
        "    \"\"\"\n",
        "    # protecci贸n: truncar prompts excesivamente largos (puedes adaptar)\n",
        "    if len(prompt) > 35000:\n",
        "        prompt = prompt[:35000]  # truncar\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=prompt\n",
        "    )\n",
        "    # depende de la librer铆a: asumo response.text contiene el string final\n",
        "    text = getattr(response, \"text\", None)\n",
        "    if text is None:\n",
        "        # intenta atributo alternativo\n",
        "        text = str(response)\n",
        "    # limitar salida\n",
        "    return text[:max_output_chars]\n"
      ],
      "metadata": {
        "id": "SeeEU2fAmg5G"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 4\n",
        "@dataclass\n",
        "class Message:\n",
        "    sender: str\n",
        "    type: str\n",
        "    payload: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "class Agent(threading.Thread):\n",
        "    \"\"\"\n",
        "    Clase base para agentes. Cada agente corre en su propio hilo y\n",
        "    consume mensajes de su cola.\n",
        "    \"\"\"\n",
        "    def __init__(self, name: str, inbox: Queue, outbox: Queue, tools: dict):\n",
        "        super().__init__(daemon=True)\n",
        "        self.name = name\n",
        "        self.inbox = inbox\n",
        "        self.outbox = outbox\n",
        "        self.tools = tools\n",
        "        self.running = True\n",
        "\n",
        "    def log(self, *args):\n",
        "        print(f\"[{self.name}]\", *args)\n",
        "\n",
        "    def stop(self):\n",
        "        self.running = False\n",
        "\n",
        "    def send(self, message: Message):\n",
        "        self.outbox.put(message)\n",
        "\n",
        "    def handle_message(self, message: Message):\n",
        "        raise NotImplementedError(\"Implementar en subclases\")\n",
        "\n",
        "    def run(self):\n",
        "        self.log(\"arrancando\")\n",
        "        while self.running:\n",
        "            try:\n",
        "                msg = self.inbox.get(timeout=1)\n",
        "            except Empty:\n",
        "                continue\n",
        "            try:\n",
        "                self.handle_message(msg)\n",
        "            except Exception as e:\n",
        "                self.log(\"error manejando mensaje:\", e)\n",
        "        self.log(\"detenido\")\n",
        "\n",
        "# --- Agentes concretos ---\n",
        "class Investigador(Agent):\n",
        "    \"\"\"\n",
        "    Busca y extrae informaci贸n de URLs/documentos, chunkea y env铆a\n",
        "    res煤menes intermedios.\n",
        "    \"\"\"\n",
        "    def handle_message(self, message: Message):\n",
        "        if message.type == \"TASK_START\":\n",
        "            # payload: { \"urls\": [...], \"max_pages\": n }\n",
        "            urls = message.payload.get(\"urls\", [])\n",
        "            docs = []\n",
        "            for url in urls:\n",
        "                try:\n",
        "                    self.log(\"extrayendo\", url)\n",
        "                    text = self.tools[\"scrape\"](url)\n",
        "                    chunks = self.tools[\"chunk\"](text)\n",
        "                    docs.append({\"url\": url, \"text\": text, \"chunks\": chunks})\n",
        "                except Exception as e:\n",
        "                    self.log(\"fallo extracci贸n:\", e)\n",
        "            # enviar resultado al redactor\n",
        "            self.send(Message(self.name, \"RESEARCH_DONE\", {\"docs\": docs}))\n",
        "\n",
        "class Redactor(Agent):\n",
        "    \"\"\"\n",
        "    Toma chunks/documentos y genera un informe preliminar.\n",
        "    Usa Gemini para redactar.\n",
        "    \"\"\"\n",
        "    def handle_message(self, message: Message):\n",
        "        if message.type == \"RESEARCH_DONE\":\n",
        "            docs = message.payload.get(\"docs\", [])\n",
        "            final_sections = []\n",
        "            for doc in docs:\n",
        "                url = doc.get(\"url\")\n",
        "                self.log(\"procesando doc\", url)\n",
        "                # resumir cada chunk y luego combinar\n",
        "                chunk_summaries = []\n",
        "                for chunk in doc.get(\"chunks\", []):\n",
        "                    prompt = (f\"Eres un redactor. Resume en 4 l铆neas el siguiente fragmento \"\n",
        "                              f\"de texto extra铆do de {url}:\\n\\n{chunk}\\n\\nResumen:\")\n",
        "                    try:\n",
        "                        resumen = generar_con_gemini(prompt)\n",
        "                    except Exception as e:\n",
        "                        resumen = f\"[ERROR en resumen: {e}]\"\n",
        "                    chunk_summaries.append(resumen)\n",
        "                # combinar res煤menes\n",
        "                combined = \"\\n\\n\".join(chunk_summaries)\n",
        "                # generar secci贸n final para ese doc\n",
        "                prompt2 = (f\"Combina y organiza los siguientes res煤menes en una secci贸n \"\n",
        "                           f\"clara y con t铆tulo para el documento {url}:\\n\\n{combined}\\n\\nSecci贸n:\")\n",
        "                try:\n",
        "                    section = generar_con_gemini(prompt2)\n",
        "                except Exception as e:\n",
        "                    section = f\"[ERROR en secci贸n: {e}]\"\n",
        "                final_sections.append({\"url\": url, \"section\": section})\n",
        "            # enviar al validador\n",
        "            self.send(Message(self.name, \"DRAFT_DONE\", {\"sections\": final_sections}))\n",
        "\n",
        "class Validador(Agent):\n",
        "    \"\"\"\n",
        "    Revisa el informe (coherencia, hechos b谩sicos) y genera una lista\n",
        "    de correcciones o aprueba.\n",
        "    \"\"\"\n",
        "    def handle_message(self, message: Message):\n",
        "        if message.type == \"DRAFT_DONE\":\n",
        "            sections = message.payload.get(\"sections\", [])\n",
        "            feedbacks = []\n",
        "            for s in sections:\n",
        "                url = s.get(\"url\")\n",
        "                sec = s.get(\"section\")\n",
        "                self.log(\"validando secci贸n de\", url)\n",
        "                prompt = (f\"Eres un revisor cr铆tico. Revisa la siguiente secci贸n \"\n",
        "                          f\"y devuelve una lista numerada de problemas (hechos err贸neos, \"\n",
        "                          f\"incoherencias, faltas importantes) o 'OK' si no hay problemas.\\n\\n{sec}\\n\\nFeedback:\")\n",
        "                try:\n",
        "                    fb = generar_con_gemini(prompt)\n",
        "                except Exception as e:\n",
        "                    fb = f\"[ERROR en validaci贸n: {e}]\"\n",
        "                feedbacks.append({\"url\": url, \"feedback\": fb})\n",
        "            # enviar feedback al orquestador para consolidaci贸n\n",
        "            self.send(Message(self.name, \"VALIDATION_DONE\", {\"feedbacks\": feedbacks}))\n"
      ],
      "metadata": {
        "id": "gqIhmX0imkdF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 5\n",
        "class Orquestador:\n",
        "    \"\"\"\n",
        "    Administra colas, agentes y flujo de trabajo:\n",
        "      - START -> Investigador -> Redactor -> Validador -> Consolidaci贸n final\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # colas: cada agente lee su propia inbox; outbox es com煤n\n",
        "        self.queues = {\n",
        "            \"investigator_inbox\": Queue(),\n",
        "            \"writer_inbox\": Queue(),\n",
        "            \"validator_inbox\": Queue(),\n",
        "            \"orchestrator_inbox\": Queue()\n",
        "        }\n",
        "        # outbox com煤n donde los agentes depositan mensajes\n",
        "        self.outbox = Queue()\n",
        "\n",
        "        # crear herramientas\n",
        "        tools = {\n",
        "            \"scrape\": extraer_texto_url,\n",
        "            \"chunk\": lambda text: chunk_text(text, chunk_size=1200, overlap=200),\n",
        "            \"save_json\": save_json\n",
        "        }\n",
        "\n",
        "        # instanciar agentes\n",
        "        self.investigator = Investigador(\"Investigador\", self.queues[\"investigator_inbox\"], self.outbox, tools)\n",
        "        self.writer = Redactor(\"Redactor\", self.queues[\"writer_inbox\"], self.outbox, tools)\n",
        "        self.validator = Validador(\"Validador\", self.queues[\"validator_inbox\"], self.outbox, tools)\n",
        "\n",
        "        self.agents = [self.investigator, self.writer, self.validator]\n",
        "        self.running = False\n",
        "        self.results = {}\n",
        "\n",
        "    def start(self):\n",
        "        self.running = True\n",
        "        for a in self.agents:\n",
        "            a.start()\n",
        "        # levantar hilo consumidor de outbox\n",
        "        self.listener = threading.Thread(target=self._listen_outbox, daemon=True)\n",
        "        self.listener.start()\n",
        "\n",
        "    def stop(self):\n",
        "        for a in self.agents:\n",
        "            a.stop()\n",
        "        self.running = False\n",
        "\n",
        "    def _listen_outbox(self):\n",
        "        while True:\n",
        "            try:\n",
        "                msg = self.outbox.get(timeout=1)\n",
        "            except Empty:\n",
        "                # si todos los agentes han completado, se podr铆a romper\n",
        "                continue\n",
        "            # distribuir mensajes\n",
        "            sender = msg.sender\n",
        "            if msg.type == \"RESEARCH_DONE\":\n",
        "                # entrega al writer\n",
        "                self.queues[\"writer_inbox\"].put(msg)\n",
        "            elif msg.type == \"DRAFT_DONE\":\n",
        "                # entrega al validator\n",
        "                self.queues[\"validator_inbox\"].put(msg)\n",
        "            elif msg.type == \"VALIDATION_DONE\":\n",
        "                # consolidar y terminar\n",
        "                self.results[\"validation\"] = msg.payload.get(\"feedbacks\", [])\n",
        "                # guardado en fichero\n",
        "                timestamp = int(time.time())\n",
        "                outpath = f\"resultado_final_{timestamp}.json\"\n",
        "                save_json(outpath, self.results)\n",
        "                print(\"[Orquestador] Resultado guardado en\", outpath)\n",
        "                # opcional: pedir al writer ajustes basados en feedback (loop)\n",
        "                # por simplicidad, paramos aqu铆:\n",
        "                self.stop()\n",
        "                break\n",
        "            else:\n",
        "                print(\"[Orquestador] Mensaje no manejado:\", msg.type)\n",
        "\n",
        "    def submit_task(self, urls: List[str]):\n",
        "        # iniciar flujo: poner mensaje TASK_START al investigador\n",
        "        msg = Message(\"Orquestador\", \"TASK_START\", {\"urls\": urls})\n",
        "        self.queues[\"investigator_inbox\"].put(msg)"
      ],
      "metadata": {
        "id": "lIuwUeVAmnel"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#celda 6\n",
        "orq = Orquestador()\n",
        "orq.start()\n",
        "\n",
        "# Ejemplo: la URL que ven铆as usando\n",
        "urls = [\n",
        "    \"https://es.wikipedia.org/wiki/Juegos_ol%C3%ADmpicos\"\n",
        "]\n",
        "\n",
        "orq.submit_task(urls)\n",
        "\n",
        "# Espera hasta que termine (en un entorno de notebook puedes esperar un poco)\n",
        "# NOTA: En producci贸n es mejor tener condici贸n m谩s robusta.\n",
        "while orq.running:\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"Proceso terminado. Revisa los archivos resultado_final_*.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKdRNtg7mqoM",
        "outputId": "461e95e6-fb9d-4685-b422-266dec101d69"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Investigador] arrancando\n",
            "[Redactor] arrancando\n",
            "[Validador] arrancando\n",
            "[Investigador] extrayendo https://es.wikipedia.org/wiki/Juegos_ol%C3%ADmpicos\n",
            "[Redactor] procesando doc https://es.wikipedia.org/wiki/Juegos_ol%C3%ADmpicos\n",
            "[Validador] validando secci贸n de https://es.wikipedia.org/wiki/Juegos_ol%C3%ADmpicos\n",
            "[Orquestador] Resultado guardado en resultado_final_1764319719.json\n",
            "[Investigador] detenido\n",
            "Proceso terminado. Revisa los archivos resultado_final_*.json\n"
          ]
        }
      ]
    }
  ]
}